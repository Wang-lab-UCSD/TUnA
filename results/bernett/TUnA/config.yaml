# Model Architecture
model:
  protein_embedding_dim: 640 # ESM2 embedding dimensions
  hid_dim: 64
  n_layers: 1 # Number of encoder and decoder layers
  n_heads: 8 # Number of attention heads
  ff_dim: 256
  dropout: 0.2
  max_sequence_length: 512  # Maximum sequence length for input data
  activation_function: "swish" # Options ["relu", "gelu", "swish", "elu", "leaky_relu", "mish"]
  gp_layer:
    rffs: 4096
    out_targets: 1
    gp_cov_momentum: -1
    gp_ridge_penalty: 1
    likelihood_function: 'binary_logistic'

# Training Parameters
training:
  subset: -1 # Number of training examples to use. Set to -1 to use all examples.
  batch_size: 16
  learning_rate: 0.0001
  weight_decay: 0.00001
  iteration: 14
 
optimizer:
  step_size: 2
  gamma: 0.93

directories:
  train_dictionary: "../../../data/embedded/bernett/Intra1_dictionary_1500_or_less/protein_dictionary.pt" # directory the embedded protein .pt files are located
  train_interactions: "../../../data/processed/bernett/Intra1_interaction_1500_or_less.tsv"
  validation_dictionary: "../../../data/embedded/bernett/Intra0_dictionary_1500_or_less/protein_dictionary.pt"
  validation_interactions: "../../../data/processed/bernett/Intra0_interaction_1500_or_less.tsv"
  test_dictionary: "../../../data/embedded/bernett/Intra2_dictionary/protein_dictionary.pt"
  test_interactions: "../../../data/processed/bernett/Intra2_interaction.tsv"
  metrics_output: "output/results.txt"
  model_output: "output/model" # Where the best model will be saved.


# Other Parameters 
other:
  random_seed: 47  # Chirp chirp!
  cuda_device: 'cuda:3'